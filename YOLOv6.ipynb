{"cells":[{"cell_type":"markdown","source":["#**You Only Look Once Model Utilization in Medical Waste Detection**  "],"metadata":{"id":"TxgO2xAqHF3P"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y8cDtxLIBHgQ","outputId":"5c606f35-e17e-4e73-ed70-01c1fbf0ef22","executionInfo":{"status":"ok","timestamp":1717570714092,"user_tz":-480,"elapsed":23,"user":{"displayName":"Muhammad Hafizuddin","userId":"01571101528823728843"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Jun  5 06:58:31 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   63C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CjpPg4mGKc1v","outputId":"65b25dc9-119f-4e1e-f490-1fe65e987066","executionInfo":{"status":"ok","timestamp":1717570719612,"user_tz":-480,"elapsed":8,"user":{"displayName":"Muhammad Hafizuddin","userId":"01571101528823728843"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["import os\n","HOME = os.getcwd()\n","print(HOME)"]},{"cell_type":"markdown","metadata":{"id":"3C3EO_2zNChu"},"source":["## Install YOLOv8\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdSMcABDNKW-","outputId":"fa658cbe-4d63-46e8-9c9f-2f5e5cc180f5","executionInfo":{"status":"ok","timestamp":1717570798578,"user_tz":-480,"elapsed":70861,"user":{"displayName":"Muhammad Hafizuddin","userId":"01571101528823728843"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.196 ðŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete âœ… (2 CPUs, 12.7 GB RAM, 29.9/201.2 GB disk)\n"]}],"source":["# Pip install method (recommended)\n","\n","!pip install ultralytics==8.0.196\n","\n","from IPython import display\n","display.clear_output()\n","\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iVvaIYEEPOty","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717570863729,"user_tz":-480,"elapsed":18116,"user":{"displayName":"Muhammad Hafizuddin","userId":"01571101528823728843"}},"outputId":"7a46678d-c27b-4a73-d5ed-34c28800f04e"},"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.196 ðŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete âœ… (2 CPUs, 12.7 GB RAM, 30.0/201.2 GB disk)\n"]}],"source":["# Git clone method (for development)\n","\n","%cd {HOME}\n","!git clone https://github.com/ultralytics/ultralytics.git\n","%cd {HOME}/ultralytics\n","!pip install -e .\n","\n","from IPython import display\n","display.clear_output()\n","\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VOEYrlBoP9-E"},"outputs":[],"source":["from ultralytics import YOLO\n","\n","from IPython.display import display, Image"]},{"cell_type":"code","source":["# show yaml file\n","#%cat /content/ultralytics/ultralytics/cfg/models/v8/yolov8.yaml\n","%cat /content/yolov6.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C9uwZwLThvhV","executionInfo":{"status":"ok","timestamp":1717570875959,"user_tz":-480,"elapsed":15,"user":{"displayName":"Muhammad Hafizuddin","userId":"01571101528823728843"}},"outputId":"05cde258-c137-4833-b58f-7355586d3b28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["# Ultralytics YOLO ðŸš€, AGPL-3.0 license\n","# YOLOv6 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/models/yolov6\n","\n","# Parameters\n","nc: 80 # number of classes\n","activation: nn.ReLU() # (optional) model default activation function\n","scales: # model compound scaling constants, i.e. 'model=yolov6n.yaml' will call yolov8.yaml with scale 'n'\n","  # [depth, width, max_channels]\n","  n: [0.33, 0.25, 1024]\n","  s: [0.33, 0.50, 1024]\n","  m: [0.67, 0.75, 768]\n","  l: [1.00, 1.00, 512]\n","  x: [1.00, 1.25, 512]\n","\n","# YOLOv6-3.0s backbone\n","backbone:\n","  # [from, repeats, module, args]\n","  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2\n","  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4\n","  - [-1, 6, Conv, [128, 3, 1]]\n","  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8\n","  - [-1, 12, Conv, [256, 3, 1]]\n","  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16\n","  - [-1, 18, Conv, [512, 3, 1]]\n","  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32\n","  - [-1, 6, Conv, [1024, 3, 1]]\n","  - [-1, 1, SPPF, [1024, 5]] # 9\n","\n","# YOLOv6-3.0s head\n","head:\n","  - [-1, 1, Conv, [256, 1, 1]]\n","  - [-1, 1, nn.ConvTranspose2d, [256, 2, 2, 0]]\n","  - [[-1, 6], 1, Concat, [1]] # cat backbone P4\n","  - [-1, 1, Conv, [256, 3, 1]]\n","  - [-1, 9, Conv, [256, 3, 1]] # 14\n","\n","  - [-1, 1, Conv, [128, 1, 1]]\n","  - [-1, 1, nn.ConvTranspose2d, [128, 2, 2, 0]]\n","  - [[-1, 4], 1, Concat, [1]] # cat backbone P3\n","  - [-1, 1, Conv, [128, 3, 1]]\n","  - [-1, 9, Conv, [128, 3, 1]] # 19\n","\n","  - [-1, 1, Conv, [128, 3, 2]]\n","  - [[-1, 15], 1, Concat, [1]] # cat head P4\n","  - [-1, 1, Conv, [256, 3, 1]]\n","  - [-1, 9, Conv, [256, 3, 1]] # 23\n","\n","  - [-1, 1, Conv, [256, 3, 2]]\n","  - [[-1, 10], 1, Concat, [1]] # cat head P5\n","  - [-1, 1, Conv, [512, 3, 1]]\n","  - [-1, 9, Conv, [512, 3, 1]] # 27\n","\n","  - [[19, 23, 27], 1, Detect, [nc]] # Detect(P3, P4, P5)\n"]}]},{"cell_type":"code","source":["#customize iPython writefile so we can write variables\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))"],"metadata":{"id":"15G0kRd1r-Su"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HnnZSm5OQfPQ"},"source":["## CLI Basics"]},{"cell_type":"markdown","metadata":{"id":"K33S7zlkQku0"},"source":["If you want to train, validate or run inference on models and don't need to make any modifications to the code, using YOLO command line interface is the easiest way to get started. Read more about CLI in [Ultralytics YOLO Docs](https://docs.ultralytics.com/usage/cli/).\n","\n","```\n","yolo task=detect    mode=train    model=yolov8n.yaml      args...\n","          classify       predict        yolov8n-cls.yaml  args...\n","          segment        val            yolov8n-seg.yaml  args...\n","                         export         yolov8n.pt        format=onnx  args...\n","```"]},{"cell_type":"markdown","source":["# Upload Dataset"],"metadata":{"id":"PHg8cp5sHfuI"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"BSd93ZJzZZKt","outputId":"fb734399-36db-4f88-d416-1057391fc8ff","executionInfo":{"status":"ok","timestamp":1717571132064,"user_tz":-480,"elapsed":222425,"user":{"displayName":"Muhammad Hafizuddin","userId":"01571101528823728843"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/datasets\n","Collecting roboflow\n","  Downloading roboflow-1.1.30-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n","  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n","  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","Collecting idna==2.10 (from roboflow)\n","  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n","Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n","  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n","Collecting python-dotenv (from roboflow)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.4)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n","Collecting requests-toolbelt (from roboflow)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-magic (from roboflow)\n","  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.52.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n","\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'opencv-python-headless' candidate (version 4.8.0.74 at https://files.pythonhosted.org/packages/76/02/f128517f3ade4bb5f71e2afd8461dba70e3f466ce745fa1fd1fade9ad1b7/opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from https://pypi.org/simple/opencv-python-headless/) (requires-python:>=3.6))\n","Reason for being yanked: deprecated, use 4.8.0.76\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: python-magic, python-dotenv, opencv-python-headless, idna, cycler, chardet, certifi, requests-toolbelt, roboflow\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.9.0.80\n","    Uninstalling opencv-python-headless-4.9.0.80:\n","      Successfully uninstalled opencv-python-headless-4.9.0.80\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.7\n","    Uninstalling idna-3.7:\n","      Successfully uninstalled idna-3.7\n","  Attempting uninstall: cycler\n","    Found existing installation: cycler 0.12.1\n","    Uninstalling cycler-0.12.1:\n","      Successfully uninstalled cycler-0.12.1\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 5.2.0\n","    Uninstalling chardet-5.2.0:\n","      Successfully uninstalled chardet-5.2.0\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2024.2.2\n","    Uninstalling certifi-2024.2.2:\n","      Successfully uninstalled certifi-2024.2.2\n","Successfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.30\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi","chardet","cv2","cycler","idna"]},"id":"8fb6db54e302487da42c98ea470513cc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in merge-1-4 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3089774/3089774 [03:06<00:00, 16587.79it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to merge-1-4 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13526/13526 [00:19<00:00, 701.95it/s]\n"]}],"source":["!mkdir {HOME}/datasets\n","%cd {HOME}/datasets\n","\n","!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"7P16sVVnxnWKeaFvCU3v\")\n","project = rf.workspace(\"hafiz-camaro\").project(\"merge-1-ilmab\")\n","version = project.version(4)\n","dataset = version.download(\"yolov8\")\n"]},{"cell_type":"code","source":["%cat {dataset.location}/data.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A1SFRHrSwBqn","executionInfo":{"status":"ok","timestamp":1717571219682,"user_tz":-480,"elapsed":851,"user":{"displayName":"Muhammad Hafizuddin","userId":"01571101528823728843"}},"outputId":"cbc62799-84b7-4326-bcb2-a3dd94faf5c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["names:\n","- blade\n","- facemask\n","- glove\n","- hand\n","- needle\n","- syringe\n","- vial\n","nc: 7\n","roboflow:\n","  license: CC BY 4.0\n","  project: merge-1-ilmab\n","  url: https://universe.roboflow.com/hafiz-camaro/merge-1-ilmab/dataset/4\n","  version: 4\n","  workspace: hafiz-camaro\n","test: test/images\n","train: train/images\n","val: valid/images\n"]}]},{"cell_type":"markdown","metadata":{"id":"YUjFBKKqXa-u"},"source":["## Custom Training"]},{"cell_type":"code","source":["# train yolov5s on custom data for 100 epochs\n","# time its performance\n","%%time\n","%cd /content\n","!python train.py --img 416 --batch 16 --epochs 100 --data {dataset.location}/data.yaml --cfg ./ultralytics/ultralytics/cfg/models/v8/yolov8.yaml --weights '' --name yolov8hafiz_results  --cache"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UQ-FOlAfvnAo","executionInfo":{"status":"ok","timestamp":1717496386829,"user_tz":-480,"elapsed":594,"user":{"displayName":"Muhammad Hafizuddin","userId":"01571101528823728843"}},"outputId":"dcf65522-f48a-44dc-8226-432a5b765282"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","python3: can't open file '/content/train.py': [Errno 2] No such file or directory\n","CPU times: user 7.76 ms, sys: 0 ns, total: 7.76 ms\n","Wall time: 108 ms\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D2YkphuiaE7_","outputId":"2258b12f-7ec2-47c8-a8c6-57a9d7c80c64","executionInfo":{"status":"ok","timestamp":1717586865094,"user_tz":-480,"elapsed":15406253,"user":{"displayName":"Muhammad Hafizuddin","userId":"01571101528823728843"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","WARNING âš ï¸ no model scale passed. Assuming scale='n'.\n","Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov6.yaml, data=/content/datasets/merge-1-4/data.yaml, epochs=25, time=None, patience=100, batch=16, imgsz=800, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train5\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 109MB/s]\n","Overriding model.yaml nc=80 with nc=7\n","WARNING âš ï¸ no model scale passed. Assuming scale='n'.\n","\u001b[34m\u001b[1mactivation:\u001b[0m nn.ReLU()\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  2     18560  ultralytics.nn.modules.conv.Conv             [32, 32, 3, 1]                \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  4    147968  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 1]                \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  6    886272  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 1]              \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  2   1180672  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 1]              \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1     16512  ultralytics.nn.modules.conv.Conv             [256, 64, 1, 1]               \n"," 11                  -1  1     16448  torch.nn.modules.conv.ConvTranspose2d        [64, 64, 2, 2, 0]             \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  1    110720  ultralytics.nn.modules.conv.Conv             [192, 64, 3, 1]               \n"," 14                  -1  3    110976  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 1]                \n"," 15                  -1  1      2112  ultralytics.nn.modules.conv.Conv             [64, 32, 1, 1]                \n"," 16                  -1  1      4128  torch.nn.modules.conv.ConvTranspose2d        [32, 32, 2, 2, 0]             \n"," 17             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1     27712  ultralytics.nn.modules.conv.Conv             [96, 32, 3, 1]                \n"," 19                  -1  3     27840  ultralytics.nn.modules.conv.Conv             [32, 32, 3, 1]                \n"," 20                  -1  1      9280  ultralytics.nn.modules.conv.Conv             [32, 32, 3, 2]                \n"," 21            [-1, 15]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 1]                \n"," 23                  -1  3    110976  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 1]                \n"," 24                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 25            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 26                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 1]              \n"," 27                  -1  3    443136  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 1]              \n"," 28        [19, 23, 27]  1    346117  ultralytics.nn.modules.head.Detect           [7, [32, 64, 128]]            \n","YOLOv6 summary: 195 layers, 4238837 parameters, 4238821 gradients, 11.9 GFLOPs\n","\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train5', view at http://localhost:6006/\n","Freezing layer 'model.28.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n","100% 6.23M/6.23M [00:00<00:00, 344MB/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/merge-1-4/train/labels... 4755 images, 5 backgrounds, 0 corrupt: 100% 4755/4755 [00:02<00:00, 2144.88it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/merge-1-4/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/merge-1-4/valid/labels... 1336 images, 0 backgrounds, 0 corrupt: 100% 1336/1336 [00:01<00:00, 1117.50it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/merge-1-4/valid/labels.cache\n","Plotting labels to runs/detect/train5/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 53 weight(decay=0.0), 62 weight(decay=0.0005), 61 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n","Image sizes 800 train, 800 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train5\u001b[0m\n","Starting training for 25 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/25      2.66G      3.094      4.543      3.871         18        800: 100% 298/298 [08:25<00:00,  1.70s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:03<00:00,  2.95s/it]\n","                   all       1336       2127     0.0559      0.239     0.0345    0.00993\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/25      2.29G      2.327      3.614      2.848         11        800: 100% 298/298 [08:07<00:00,  1.64s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [01:58<00:00,  2.83s/it]\n","                   all       1336       2127      0.199      0.264      0.162     0.0758\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/25      2.27G      1.902      2.912      2.386         12        800: 100% 298/298 [08:06<00:00,  1.63s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:01<00:00,  2.89s/it]\n","                   all       1336       2127      0.568      0.269      0.244      0.126\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/25      2.26G      1.669      2.503       2.14          4        800: 100% 298/298 [08:11<00:00,  1.65s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:04<00:00,  2.97s/it]\n","                   all       1336       2127       0.52      0.408      0.385      0.233\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/25      2.25G      1.536      2.288      2.005          8        800: 100% 298/298 [08:13<00:00,  1.66s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:01<00:00,  2.90s/it]\n","                   all       1336       2127      0.496      0.544      0.482      0.302\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/25      2.25G      1.442      2.103        1.9          9        800: 100% 298/298 [08:10<00:00,  1.65s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:01<00:00,  2.89s/it]\n","                   all       1336       2127      0.542      0.537      0.569      0.379\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/25      2.27G      1.374      1.975      1.828          8        800: 100% 298/298 [08:05<00:00,  1.63s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:00<00:00,  2.88s/it]\n","                   all       1336       2127      0.574      0.567      0.601      0.421\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/25      2.26G      1.324      1.855      1.776         11        800: 100% 298/298 [08:13<00:00,  1.66s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [01:58<00:00,  2.82s/it]\n","                   all       1336       2127      0.627      0.615       0.66      0.463\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/25      2.26G      1.282      1.777      1.732          6        800: 100% 298/298 [08:09<00:00,  1.64s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:03<00:00,  2.94s/it]\n","                   all       1336       2127      0.611      0.623      0.658      0.462\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/25      2.26G      1.246      1.673      1.693         11        800: 100% 298/298 [08:11<00:00,  1.65s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:03<00:00,  2.94s/it]\n","                   all       1336       2127      0.727      0.695      0.749      0.521\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/25      2.27G      1.196      1.591      1.645          9        800: 100% 298/298 [08:13<00:00,  1.66s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:04<00:00,  2.97s/it]\n","                   all       1336       2127       0.73      0.697      0.758      0.553\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/25      2.26G       1.17      1.547      1.622          9        800: 100% 298/298 [08:06<00:00,  1.63s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:05<00:00,  3.00s/it]\n","                   all       1336       2127      0.758      0.715      0.791      0.568\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/25      2.25G      1.155      1.505      1.601         12        800: 100% 298/298 [08:22<00:00,  1.69s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:05<00:00,  2.98s/it]\n","                   all       1336       2127       0.74      0.701      0.771      0.564\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/25      2.26G      1.132      1.438      1.576         15        800: 100% 298/298 [08:23<00:00,  1.69s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [01:59<00:00,  2.84s/it]\n","                   all       1336       2127      0.804       0.76      0.832      0.607\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/25      2.26G      1.123      1.382      1.561          8        800: 100% 298/298 [08:01<00:00,  1.62s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:02<00:00,  2.91s/it]\n","                   all       1336       2127      0.777      0.766      0.839       0.62\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/25      2.24G      0.966      1.127      1.482          3        800: 100% 298/298 [08:28<00:00,  1.71s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [01:59<00:00,  2.85s/it]\n","                   all       1336       2127      0.821      0.782      0.852      0.627\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/25      2.24G     0.9384      1.068      1.456          3        800: 100% 298/298 [07:42<00:00,  1.55s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:02<00:00,  2.91s/it]\n","                   all       1336       2127      0.847      0.762      0.853       0.64\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/25      2.25G     0.9023      1.007      1.418          4        800: 100% 298/298 [07:53<00:00,  1.59s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [01:58<00:00,  2.83s/it]\n","                   all       1336       2127      0.847      0.814      0.887      0.673\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/25      2.24G     0.8789     0.9315      1.397          6        800: 100% 298/298 [07:48<00:00,  1.57s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:02<00:00,  2.91s/it]\n","                   all       1336       2127      0.873      0.789      0.893      0.685\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/25      2.26G     0.8522     0.8975      1.367          7        800: 100% 298/298 [07:46<00:00,  1.57s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:00<00:00,  2.86s/it]\n","                   all       1336       2127      0.896      0.835      0.912      0.704\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      21/25      2.24G     0.8298     0.8567      1.347          3        800: 100% 298/298 [07:55<00:00,  1.60s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [01:57<00:00,  2.81s/it]\n","                   all       1336       2127      0.895      0.851      0.917      0.715\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      22/25      2.24G     0.8163     0.8353      1.333          7        800: 100% 298/298 [08:01<00:00,  1.61s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:01<00:00,  2.88s/it]\n","                   all       1336       2127      0.897      0.864      0.921      0.725\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      23/25      2.24G     0.7898     0.7845      1.318          5        800: 100% 298/298 [07:43<00:00,  1.55s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:02<00:00,  2.93s/it]\n","                   all       1336       2127      0.921      0.857       0.93      0.736\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      24/25      2.24G     0.7821     0.7665        1.3          5        800: 100% 298/298 [08:01<00:00,  1.62s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:00<00:00,  2.87s/it]\n","                   all       1336       2127      0.923       0.86      0.931      0.741\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      25/25      2.24G      0.756     0.7309      1.281          5        800: 100% 298/298 [08:03<00:00,  1.62s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:02<00:00,  2.93s/it]\n","                   all       1336       2127       0.91      0.887      0.935      0.748\n","\n","25 epochs completed in 4.232 hours.\n","Optimizer stripped from runs/detect/train5/weights/last.pt, 8.7MB\n","Optimizer stripped from runs/detect/train5/weights/best.pt, 8.7MB\n","\n","Validating runs/detect/train5/weights/best.pt...\n","Ultralytics YOLOv8.2.28 ðŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:952: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv_transpose2d(\n","YOLOv6 summary (fused): 142 layers, 4234437 parameters, 0 gradients, 11.8 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 42/42 [02:04<00:00,  2.96s/it]\n","                   all       1336       2127      0.909      0.887      0.935      0.748\n","                 blade        193        326      0.917      0.955      0.975      0.835\n","              facemask        431        443      0.907       0.93       0.96      0.838\n","                 glove        240        258      0.937      0.925      0.966      0.889\n","                  hand        209        227      0.907        0.9      0.954      0.736\n","                needle        252        280      0.941      0.846      0.894       0.59\n","               syringe        286        309      0.853      0.799      0.871      0.627\n","                  vial        134        284      0.901      0.852      0.927      0.721\n","Speed: 0.3ms preprocess, 3.2ms inference, 0.0ms loss, 2.6ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train5\u001b[0m\n","ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"]}],"source":["%cd {HOME}\n","\n","!yolo task=detect mode=train model=yolov6.yaml data={dataset.location}/data.yaml epochs=25 imgsz=800 plots=True"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"MTOkEEQlYDIP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717589038075,"user_tz":-480,"elapsed":25481,"user":{"displayName":"Muhammad Hafizuddin","userId":"01571101528823728843"}},"outputId":"38097d0f-ed18-4ac8-f30b-b7b03dd11d60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1N9Jw3iuKli1iq7qhUK8sflE28B4qmvPR","timestamp":1717570656764},{"file_id":"1kTFCBwC9mWPXcTwfi0RJhYLjyxcYBU9m","timestamp":1715143121442},{"file_id":"https://github.com/roboflow-ai/notebooks/blob/main/notebooks/train-yolov8-object-detection-on-custom-dataset.ipynb","timestamp":1711986725920}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}